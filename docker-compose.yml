version: "2.1"
services:

  vllm-env:
    build:
      context: ./image
      args:
        HF_TOKEN: ${TOKEN}
        VSCODE_COMMIT_ID: ${VSCODE_COMMIT_ID}
    runtime: nvidia
    cpuset: "0-10"
    mem_limit: 20g
    memswap_limit: 40g
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - HF_TOKEN=${TOKEN}
    volumes:
      - ./cache:/root/.cache:rw
    ports:
      - "8000:8000"
      - "222:22"
    #command: tail -f /dev/null
    #entrypoint: >
    #python3.12 -m vllm.entrypoints.openai.api_server --model openai/gpt-oss-20b --gpu-memory-utilization 0.9 --max-model-len 1024 --max-num-seqs 1 --port 8000

